 **WikiText-103** :

* **Content** : **Comprised of over 100 million tokens extracted from verified Good and Featured articles on Wikipedia.**[huggingface.co**+4**paperswithcode.com**+4**salesforce.com**+4**](https://paperswithcode.com/dataset/wikitext-103)
* **Size** : **Significantly larger than the Penn Treebank (PTB); WikiText-2 is over twice as large, and WikiText-103 is over 110 times larger.**[huggingface.co**+5**paperswithcode.com**+5**huggingface.co**+5**](https://paperswithcode.com/dataset/wikitext-103)
* **Features** : **Maintains original case, punctuation, and numbers, unlike PTB, which removes these elements.**[dax-cdn.cdn.appdomain.cloud**+6**salesforce.com**+6**paperswithcode.com**+6**](https://www.salesforce.com/blog/the-wikitext-long-term-dependency-language-modeling-dataset/)
* **Usage** : **Ideal for models that leverage long-term dependencies due to its composition of full articles.**[dagshub.com**+5**huggingface.co**+5**salesforce.com**+5**](https://huggingface.co/datasets/Salesforce/wikitext/blob/main/README.md)
* **Availability** : **Accessible under the Creative Commons Attribution-ShareAlike License.**
